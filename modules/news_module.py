import requests
from bs4 import BeautifulSoup
import datetime
import asyncio
import os
from telegram import Update
from telegram.ext import ContextTypes
from newspaper import Article  # âœ… Ø¨Ø±Ø§ÛŒ Ú¯Ø±ÙØªÙ† Ù…ØªÙ† Ùˆ Ø®Ù„Ø§ØµÙ‡ Ø®Ø¨Ø±

# ğŸŒ Ú¯Ø±ÙØªÙ† Ø§Ø®Ø¨Ø§Ø± ÙØ§Ø±Ø³ÛŒ Ø§Ø² Google News
def fetch_persian_news(query="Ø§Ø®Ø¨Ø§Ø± Ø§ÛŒØ±Ø§Ù†"):
    urls = [
        f"https://news.google.com/rss/search?q={query}+when:1d&hl=fa&gl=IR&ceid=IR:fa",
        f"https://news.google.com/rss/search?q={query}+when:1d&hl=fa&gl=AF&ceid=AF:fa",
    ]

    for url in urls:
        try:
            response = requests.get(url, timeout=10)
            response.encoding = "utf-8"
            soup = BeautifulSoup(response.text, "xml")
            items = soup.find_all("item")
            if items:
                news_list = []
                for item in items[:5]:  # ÙÙ‚Ø· Ûµ ØªØ§ Ø®Ø¨Ø± Ø¬Ø¯ÛŒØ¯
                    title = item.title.text
                    link = item.link.text
                    pub_date = item.pubDate.text
                    news_list.append((title, link, pub_date))
                return news_list
        except Exception as e:
            print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø²:", url, "|", e)
            continue
    return []


# âœï¸ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ø² Ù„ÛŒÙ†Ú© Ø®Ø¨Ø±
def summarize_article(url):
    try:
        article = Article(url, language='fa')
        article.download()
        article.parse()
        article.nlp()
        return article.summary if article.summary else article.text[:400]
    except Exception:
        return None


# ğŸ“¢ ÙØ±Ù…Ø§Ù† Ø±Ø¨Ø§Øª Ø¨Ø±Ø§ÛŒ Ú¯Ø±ÙØªÙ† Ø®Ø¨Ø±
async def get_news(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.message.text.replace("Ø§Ø®Ø¨Ø§Ø±", "").strip() or "Ø§ÛŒØ±Ø§Ù†"
    news = fetch_persian_news(query)

    if not news:
        await update.message.reply_text("âš ï¸ Ø®Ø¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ú¯ÙˆÚ¯Ù„ Ù†ÛŒÙˆØ² Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª.")
        return

    msg = f"ğŸ“° <b>Ø¢Ø®Ø±ÛŒÙ† Ø®Ø¨Ø±Ù‡Ø§ÛŒ {query}</b>\n\n"
    for title, link, pub in news:
        summary = summarize_article(link)
        msg += f"ğŸ— <b>{title}</b>\n"
        if summary:
            msg += f"{summary}\n"
        msg += f"ğŸ•’ {pub}\n\n"
        msg += "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"

    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
    msg += f"ğŸ“… Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ: <i>{now}</i>"

    await update.message.reply_html(msg[:3900])


# â° Ø§Ø±Ø³Ø§Ù„ Ø®ÙˆØ¯Ú©Ø§Ø± Ø®Ø¨Ø± Ø¯Ø§Øº Ø³Ø§Ø¹Øª Û¹ ØµØ¨Ø­
async def start_daily_news_scheduler(bot):
    while True:
        now = datetime.datetime.now()
        if now.hour == 9 and now.minute == 0:
            chat_id = os.getenv("NEWS_CHAT_ID")
            if chat_id:
                news = fetch_persian_news("Ø®Ø¨Ø± Ø¯Ø§Øº Ø§ÛŒØ±Ø§Ù†")
                if news:
                    first = news[0]
                    summary = summarize_article(first[1])
                    msg = f"ğŸ”¥ <b>Ø®Ø¨Ø± Ø¯Ø§Øº Ø§Ù…Ø±ÙˆØ²:</b>\n\nğŸ— {first[0]}\n\n{summary or 'Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.'}"
                    await bot.send_message(chat_id, msg, parse_mode="HTML")
        await asyncio.sleep(60)
