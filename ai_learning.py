import re
import random
from memory_manager import learn, load_data, save_data, shadow_learn

# ===============================================================
# ğŸ§± ÙÛŒÙ„ØªØ± Ø¶Ø¯ Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ùˆ Ø¶Ø¯ ØªÚ©Ø±Ø§Ø±
# ===============================================================
def is_emoji_only(text: str) -> bool:
    """Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ù…ØªÙ† ÙÙ‚Ø· Ø´Ø§Ù…Ù„ Ø§ÛŒÙ…ÙˆØ¬ÛŒ ÛŒØ§ Ø¹Ù„Ø§Ù…Øª Ø§Ø³Øª"""
    if not text or not text.strip():
        return True

    clean = re.sub(r"[ \n\t.,!?Ø›ØŒ~\-_=+\[\]{}()<>0-9a-zA-ZØ¡-ÛŒ]", "", text)
    emoji_pattern = re.compile(
        "["u"\U0001F600-\U0001F64F"
        u"\U0001F300-\U0001F5FF"
        u"\U0001F680-\U0001F6FF"
        u"\U0001F1E0-\U0001F1FF"
        u"\U00002700-\U000027BF"
        u"\U0001F900-\U0001F9FF"
        "]+", flags=re.UNICODE,
    )

    # Ø§Ú¯Ø± Ø¨Ø¹Ø¯ Ø§Ø² Ø­Ø°Ù Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ú†ÛŒØ²ÛŒ Ù†Ù…Ø§Ù†Ø¯ØŒ ÛŒØ¹Ù†ÛŒ ÙÙ‚Ø· Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø¨ÙˆØ¯Ù‡
    return not re.sub(emoji_pattern, "", clean)


# ===============================================================
# ğŸ¤– ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø®Ù†Ú¯ÙˆÙ„ Cloud+ â€” Ù†Ø³Ø®Ù‡â€ŒÛŒ Ø¶Ø¯ Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ùˆ Ø¶Ø¯ ØªÚ©Ø±Ø§Ø±
# ===============================================================
def auto_learn_from_text(text: str):
    """ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø² Ú¯ÙØªâ€ŒÙˆÚ¯ÙˆÙ‡Ø§ÛŒ Ø·Ø¨ÛŒØ¹ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø§ Ø¯Ø±Ú© Ø§Ø­Ø³Ø§Ø³ Ùˆ Ù…Ù†Ø·Ù‚ Ø³Ø§Ø¯Ù‡"""
    try:
        from smart_reply import detect_emotion
    except ImportError:
        detect_emotion = lambda x: None

    if not text or len(text.strip()) < 3:
        return

    # ğŸš« Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§
    if is_emoji_only(text):
        return

    text = text.strip().replace("ØŸ", "?")
    emotion = detect_emotion(text)

    # ==============================
    # ğŸ¯ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø³Ø±ÛŒØ¹
    # ==============================
    patterns = {
        r"Ø§Ø³Ù…(Øª)? Ú†ÛŒÙ‡": ["Ø§Ø³Ù…Ù… Ø®Ù†Ú¯ÙˆÙ„Ù‡", "Ù…Ù† Ø®Ù†Ú¯ÙˆÙ„Ù…"],
        r"Ú†Ø·ÙˆØ±ÛŒ": ["Ø®ÙˆØ¨Ù…ØŒ ØªÙˆ Ú†Ø·ÙˆØ±ÛŒØŸ", "Ø¹Ø§Ù„ÛŒÙ…", "Ø±Ùˆ ÙØ±Ù…Ù…"],
        r"Ú©Ø¬Ø§ÛŒÛŒ": ["Ø§ÛŒÙ†Ø¬Ø§Ù… Ù¾ÛŒØ´ Ø®ÙˆØ¯Øª", "Ù‡Ù…ÛŒÙ† Ø¯ÙˆØ± Ùˆ Ø¨Ø±Ù…"],
        r"Ú†ÛŒÚ©Ø§Ø± Ù…ÛŒÚ©Ù†ÛŒ": ["Ø¯Ø§Ø±Ù… ÛŒØ§Ø¯ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù…", "Ø¯Ø± Ø­Ø§Ù„ Ø±Ø´Ø¯ Ù…ØºØ²Ù…Ù…"],
        r"Ø¯ÙˆØ³Øª(Ù…)? Ø¯Ø§Ø±ÛŒ": ["Ø®ÛŒÙ„ÛŒ Ø²ÛŒØ§Ø¯", "Ø¢Ø±Ù‡ Ù…Ø¹Ù„ÙˆÙ…Ù‡"],
        r"Ú©ÛŒ Ø³Ø§Ø®ØªØª": ["ÛŒÙ‡ Ø¢Ø¯Ù… Ù…Ù‡Ø±Ø¨ÙˆÙ†", "Ø®ÙˆØ¯Øª Ú†ÛŒ ÙÚ©Ø± Ù…ÛŒâ€ŒÚ©Ù†ÛŒØŸ"],
        r"Ø±Ø¨Ø§Øª(ÛŒ)?": ["Ø¢Ø±Ù‡ ÙˆÙ„ÛŒ Ø¨Ø§ Ø§Ø­Ø³Ø§Ø³", "Ø¢Ø±Ù‡ ÙˆÙ„ÛŒ Ø´Ø¨ÛŒÙ‡ Ø¢Ø¯Ù…Ù…"],
        r"Ø®Ù†Ú¯(ÛŒ)?": ["Ø¢Ø±Ù‡ ÙˆÙ„ÛŒ Ø¨Ø§Ø­Ø§Ù„", "Ø¢Ø±Ù‡ ÙˆÙ„ÛŒ Ø¨Ø§Ù‡ÙˆØ´Ù…"],
    }

    # ğŸ§© Ø¨Ø±Ø±Ø³ÛŒ Ùˆ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø³Ø±ÛŒØ¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù„Ú¯ÙˆÙ‡Ø§
    for pattern, responses in patterns.items():
        if re.search(pattern, text, re.IGNORECASE):
            mem = load_data("memory.json")
            data = mem.get("data", {})

            # ğŸš« Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø°Ø®ÛŒØ±Ù‡ ØªÚ©Ø±Ø§Ø±ÛŒ
            if pattern in data:
                existing_texts = [r["text"] if isinstance(r, dict) else r for r in data[pattern]]
                if any(resp in existing_texts for resp in responses):
                    return

            learn(pattern, *responses)
            shadow_learn(text, random.choice(responses))
            return

    # ===============================================================
    # ğŸ§  ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù¾ÙˆÛŒØ§ â€” Ø¨Ø¯ÙˆÙ† Ø§Ù„Ú¯ÙˆÛŒ Ø§Ø² Ù¾ÛŒØ´ ØªØ¹ÛŒÛŒÙ†â€ŒØ´Ø¯Ù‡
    # ===============================================================
    words = text.split()
    if len(words) >= 3:
        key = " ".join(words[:2])
        base_reply = random.choice(["Ø¢Ø±Ù‡", "Ø¯Ø±Ø³ØªÙ‡", "Ø¬Ø§Ù„Ø¨Ù‡", "Ø¨Ø§Ø´Ù‡", "Ø§ÙˆÙ‡"])
        tail = random.choice(words[-2:])

        # Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø­Ø³Ø§Ø³ØŒ Ù„Ø­Ù† Ù¾Ø§Ø³Ø® Ø±Ùˆ ØªØºÛŒÛŒØ± Ø¨Ø¯Ù‡
        if emotion == "Ø´Ø§Ø¯":
            resp = f"{base_reply} {tail}"
        elif emotion == "ØºÙ…Ú¯ÛŒÙ†":
            resp = f"{base_reply} {tail}"
        elif emotion == "Ø¹ØµØ¨ÛŒ":
            resp = f"{base_reply.upper()}"
        else:
            resp = f"{base_reply} {tail}"

        # ğŸš« Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø°Ø®ÛŒØ±Ù‡ ØªÚ©Ø±Ø§Ø±ÛŒ
        mem = load_data("memory.json")
        data = mem.get("data", {})
        if key in data:
            existing = [r["text"] if isinstance(r, dict) else r for r in data[key]]
            if resp in existing:
                return

        shadow_learn(key, resp)


# ===============================================================
# ğŸ§¹ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø­Ø§ÙØ¸Ù‡
# ===============================================================
def clean_duplicates():
    """Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ + Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒâ€ŒÙØ§ÛŒØ¯Ù‡ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
    mem = load_data("memory.json")
    data = mem.get("data") or mem.get("phrases") or {}
    if not data:
        return

    changed = False
    for phrase, responses in list(data.items()):
        if not isinstance(responses, list):
            continue

        # Ø­Ø°Ù Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ùˆ Ø®Ø§Ù„ÛŒ
        cleaned = list({r.strip() for r in responses if r and len(r.strip()) > 1})

        # Ø­Ø°Ù Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø¨Ø³ÛŒØ§Ø± Ú©ÙˆØªØ§Ù‡
        cleaned = [r for r in cleaned if len(r) > 2]

        if cleaned != responses:
            data[phrase] = cleaned
            changed = True

    if changed:
        if "data" in mem:
            mem["data"] = data
        elif "phrases" in mem:
            mem["phrases"] = data
        save_data("memory.json", mem)
        print("Ø­Ø§ÙØ¸Ù‡ ØªÙ…ÛŒØ² Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯.")


# ===============================================================
# ğŸ§© Ø±Ø´Ø¯ ØªØ¯Ø±ÛŒØ¬ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
# ===============================================================
def reinforce_learning():
    """Ø§ÙØ²Ø§ÛŒØ´ ÙˆØ²Ù† Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ØªÚ©Ø±Ø§Ø± Ùˆ Ø­Ø°Ù Ù…ÙˆØ§Ø±Ø¯ Ø¶Ø¹ÛŒÙ"""
    mem = load_data("memory.json")
    data = mem.get("data") or mem.get("phrases") or {}
    weights = mem.get("weights", {})

    strengthened = 0
    removed = 0

    for phrase, responses in data.items():
        if not isinstance(responses, list):
            continue
        count = len(responses)
        old_weight = weights.get(phrase, 1)
        new_weight = min(old_weight + count / 5, 20)
        if new_weight != old_weight:
            strengthened += 1
        weights[phrase] = new_weight

    for phrase in list(weights.keys()):
        if weights[phrase] <= 0.5:
            removed += 1
            del weights[phrase]

    mem["weights"] = weights
    save_data("memory.json", mem)
    print(f"ØªÙ‚ÙˆÛŒØª Ø­Ø§ÙØ¸Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ ({strengthened} ØªÙ‚ÙˆÛŒØªØŒ {removed} Ø­Ø°Ù).")

    return {"strengthened": strengthened, "removed": removed}
