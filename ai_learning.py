import re
import random
from memory_manager import learn, load_data, save_data, shadow_learn

# ===============================================================
# ğŸ¤– ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø®Ù†Ú¯ÙˆÙ„ Cloud+ â€” Ù†Ø³Ø®Ù‡â€ŒÛŒ Ø¨Ø¯ÙˆÙ† Ø§ÛŒÙ…ÙˆØ¬ÛŒ
# ===============================================================
def auto_learn_from_text(text: str):
    """ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø² Ú¯ÙØªâ€ŒÙˆÚ¯ÙˆÙ‡Ø§ÛŒ Ø·Ø¨ÛŒØ¹ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø§ Ø¯Ø±Ú© Ø§Ø­Ø³Ø§Ø³ Ùˆ Ù…Ù†Ø·Ù‚ Ø³Ø§Ø¯Ù‡"""
    # âš™ï¸ import Ø¯Ø§Ø®Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø­Ù„Ù‚Ù‡â€ŒÛŒ import
    try:
        from smart_reply import detect_emotion
    except ImportError:
        detect_emotion = lambda x: None  # Ø§Ú¯Ø± Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø¨ÙˆØ¯ØŒ Ø§Ø­Ø³Ø§Ø³ Ø±Ùˆ Ø®Ù†Ø«ÛŒ Ú©Ù†

    if not text or len(text) < 3:
        return

    text = text.strip().replace("ØŸ", "?")
    emotion = detect_emotion(text)  # ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³ Ø¬Ù…Ù„Ù‡ (Ø´Ø§Ø¯ØŒ ØºÙ…Ú¯ÛŒÙ†ØŒ Ø¹ØµØ¨ÛŒØŒ Ø®Ù†Ø«ÛŒ)

    # ==============================
    # ğŸ¯ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø³Ø±ÛŒØ¹
    # ==============================
    patterns = {
        r"Ø§Ø³Ù…(Øª)? Ú†ÛŒÙ‡": ["Ø§Ø³Ù…Ù… Ø®Ù†Ú¯ÙˆÙ„Ù‡", "Ù…Ù† Ø®Ù†Ú¯ÙˆÙ„Ù…"],
        r"Ú†Ø·ÙˆØ±ÛŒ": ["Ø®ÙˆØ¨Ù…ØŒ ØªÙˆ Ú†Ø·ÙˆØ±ÛŒØŸ", "Ø¹Ø§Ù„ÛŒÙ…", "Ø±Ùˆ ÙØ±Ù…Ù…"],
        r"Ú©Ø¬Ø§ÛŒÛŒ": ["Ø§ÛŒÙ†Ø¬Ø§Ù… Ù¾ÛŒØ´ Ø®ÙˆØ¯Øª", "Ù‡Ù…ÛŒÙ† Ø¯ÙˆØ± Ùˆ Ø¨Ø±Ù…"],
        r"Ú†ÛŒÚ©Ø§Ø± Ù…ÛŒÚ©Ù†ÛŒ": ["Ø¯Ø§Ø±Ù… ÛŒØ§Ø¯ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù…", "Ø¯Ø± Ø­Ø§Ù„ Ø±Ø´Ø¯ Ù…ØºØ²Ù…Ù…"],
        r"Ø¯ÙˆØ³Øª(Ù…)? Ø¯Ø§Ø±ÛŒ": ["Ø®ÛŒÙ„ÛŒ Ø²ÛŒØ§Ø¯", "Ø¢Ø±Ù‡ Ù…Ø¹Ù„ÙˆÙ…Ù‡"],
        r"Ú©ÛŒ Ø³Ø§Ø®ØªØª": ["ÛŒÙ‡ Ø¢Ø¯Ù… Ù…Ù‡Ø±Ø¨ÙˆÙ†", "Ø®ÙˆØ¯Øª Ú†ÛŒ ÙÚ©Ø± Ù…ÛŒâ€ŒÚ©Ù†ÛŒØŸ"],
        r"Ø±Ø¨Ø§Øª(ÛŒ)?": ["Ø¢Ø±Ù‡ ÙˆÙ„ÛŒ Ø¨Ø§ Ø§Ø­Ø³Ø§Ø³", "Ø¢Ø±Ù‡ ÙˆÙ„ÛŒ Ø´Ø¨ÛŒÙ‡ Ø¢Ø¯Ù…Ù…"],
        r"Ø®Ù†Ú¯(ÛŒ)?": ["Ø¢Ø±Ù‡ ÙˆÙ„ÛŒ Ø¨Ø§Ø­Ø§Ù„", "Ø¢Ø±Ù‡ ÙˆÙ„ÛŒ Ø¨Ø§Ù‡ÙˆØ´Ù…"],
    }

    # ğŸ§© Ø¨Ø±Ø±Ø³ÛŒ Ùˆ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø³Ø±ÛŒØ¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù„Ú¯ÙˆÙ‡Ø§
    for pattern, responses in patterns.items():
        if re.search(pattern, text, re.IGNORECASE):
            learn(pattern, *responses)
            shadow_learn(text, random.choice(responses))
            return

    # ===============================================================
    # ğŸ§  ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù¾ÙˆÛŒØ§ â€” Ø¨Ø¯ÙˆÙ† Ø§Ù„Ú¯ÙˆÛŒ Ø§Ø² Ù¾ÛŒØ´ ØªØ¹ÛŒÛŒÙ†â€ŒØ´Ø¯Ù‡
    # ===============================================================
    words = text.split()
    if len(words) >= 3:
        # Ú©Ù„ÛŒØ¯ Ø§ØµÙ„ÛŒ Ø§Ø² Ø¯Ùˆ ÙˆØ§Ú˜Ù‡ Ø§ÙˆÙ„ Ø¬Ù…Ù„Ù‡ Ø³Ø§Ø®ØªÙ‡ Ù…ÛŒØ´Ù‡ (Ø¨Ù‡ØªØ± Ø§Ø² ÙÙ‚Ø· ÛŒÚ© Ú©Ù„Ù…Ù‡)
        key = " ".join(words[:2])
        base_reply = random.choice(["Ø¢Ø±Ù‡", "Ø¯Ø±Ø³ØªÙ‡", "Ø¬Ø§Ù„Ø¨Ù‡", "Ø¨Ø§Ø´Ù‡", "Ø§ÙˆÙ‡"])
        tail = random.choice(words[-2:])

        # Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø­Ø³Ø§Ø³ØŒ Ù„Ø­Ù† Ù¾Ø§Ø³Ø® Ø±Ùˆ ØªØºÛŒÛŒØ± Ø¨Ø¯Ù‡ (Ø¨Ø¯ÙˆÙ† Ø§ÛŒÙ…ÙˆØ¬ÛŒ)
        if emotion == "Ø´Ø§Ø¯":
            resp = f"{base_reply} {tail}"
        elif emotion == "ØºÙ…Ú¯ÛŒÙ†":
            resp = f"{base_reply} {tail}"
        elif emotion == "Ø¹ØµØ¨ÛŒ":
            resp = f"{base_reply.upper()}"
        else:
            resp = f"{base_reply} {tail}"

        shadow_learn(key, resp)


# ===============================================================
# ğŸ§¹ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø­Ø§ÙØ¸Ù‡ (Ù†Ø³Ø®Ù‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡)
# ===============================================================
def clean_duplicates():
    """Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ + Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒâ€ŒÙØ§ÛŒØ¯Ù‡ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
    mem = load_data("memory.json")

    # Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨Ø§ Ù‡Ø± Ù†ÙˆØ¹ Ø³Ø§Ø®ØªØ§Ø± Ø­Ø§ÙØ¸Ù‡
    data = mem.get("data") or mem.get("phrases") or {}
    if not data:
        return

    changed = False
    for phrase, responses in list(data.items()):
        if not isinstance(responses, list):
            continue

        # Ø­Ø°Ù Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ùˆ Ø®Ø§Ù„ÛŒ
        cleaned = list({r.strip() for r in responses if r and len(r.strip()) > 1})

        # Ø­Ø°Ù Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø¨Ø³ÛŒØ§Ø± Ú©ÙˆØªØ§Ù‡ Ù…Ø«Ù„ "Ø¢Ù‡" ÛŒØ§ "Ù‡Ø§"
        cleaned = [r for r in cleaned if len(r) > 2]

        # Ø¯Ø± ØµÙˆØ±Øª ØªØºÛŒÛŒØ± Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¬Ø¯Ø¯
        if cleaned != responses:
            data[phrase] = cleaned
            changed = True

    if changed:
        # Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªÙ…ÛŒØ² Ø¯Ø± Ù‡Ù…Ø§Ù† Ø³Ø§Ø®ØªØ§Ø± Ø§ØµÙ„ÛŒ
        if "data" in mem:
            mem["data"] = data
        elif "phrases" in mem:
            mem["phrases"] = data
        save_data("memory.json", mem)
        print("Ø­Ø§ÙØ¸Ù‡ ØªÙ…ÛŒØ² Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯.")


# ===============================================================
# ğŸ§© Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø±Ø´Ø¯ Ø®ÙˆØ¯Ú©Ø§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
# ===============================================================
def reinforce_learning():
    """
    Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø±Ø´Ø¯ ØªØ¯Ø±ÛŒØ¬ÛŒ â€” Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ú†Ù†Ø¯ Ø¨Ø§Ø± Ø¯ÛŒØ¯Ù‡ Ø´Ø¯Ù† ØªÙ‚ÙˆÛŒØª Ù…ÛŒâ€ŒØ´Ù†.
    Ø¨Ø§Ø¹Ø« Ù…ÛŒØ´Ù‡ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ØªÚ©Ø±Ø§Ø± Ù‚ÙˆÛŒâ€ŒØªØ± Ùˆ Ø·Ø¨ÛŒØ¹ÛŒâ€ŒØªØ± Ø´Ù†.
    """
    mem = load_data("memory.json")
    data = mem.get("data") or mem.get("phrases") or {}
    weights = mem.get("weights", {})

    strengthened = 0
    removed = 0

    for phrase, responses in data.items():
        if not isinstance(responses, list):
            continue
        count = len(responses)
        old_weight = weights.get(phrase, 1)
        new_weight = min(old_weight + count / 5, 20)
        if new_weight != old_weight:
            strengthened += 1
        weights[phrase] = new_weight

    # Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒâ€ŒØ§Ø³ØªÙØ§Ø¯Ù‡
    for phrase in list(weights.keys()):
        if weights[phrase] <= 0.5:
            removed += 1
            del weights[phrase]

    mem["weights"] = weights
    save_data("memory.json", mem)
    print(f"ØªÙ‚ÙˆÛŒØª Ø­Ø§ÙØ¸Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ ({strengthened} ØªÙ‚ÙˆÛŒØªØŒ {removed} Ø­Ø°Ù).")

    return {"strengthened": strengthened, "removed": removed}
