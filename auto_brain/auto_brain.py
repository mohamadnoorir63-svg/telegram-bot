# auto_brain.py
import asyncio
import json
import os
import random
from datetime import datetime

from memory_manager import (
    load_data, save_data, generate_sentence, evaluate_intelligence,
    reinforce_learning, get_stats
)
from ai_learning import clean_duplicates, auto_learn_from_text
from fix_memory import fix_json

ADMIN_ID = int(os.getenv("ADMIN_ID", "8588347189"))
BRAIN_STATS_FILE = "auto_brain/brain_stats.json"


# ------------------------------
# ğŸ“Š Ø¢Ù…Ø§Ø±
# ------------------------------
def load_stats():
    if not os.path.exists(BRAIN_STATS_FILE):
        return {"phrases": 0, "responses": 0, "runs": 0, "last_update": ""}
    try:
        with open(BRAIN_STATS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {"phrases": 0, "responses": 0, "runs": 0, "last_update": ""}


def save_stats(stats):
    try:
        with open(BRAIN_STATS_FILE, "w", encoding="utf-8") as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"[AutoBrain] Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¢Ù…Ø§Ø±: {e}")


# ------------------------------
# ğŸ›  ØªØ¹Ù…ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø­Ø§ÙØ¸Ù‡
# ------------------------------
def ensure_memory_files():
    for file in ["memory.json", "shadow_memory.json"]:
        fix_json(file)


# ------------------------------
# ğŸ” Ø§Ø¯ØºØ§Ù… Ø­Ø§ÙØ¸Ù‡ Ø³Ø§ÛŒÙ‡
# ------------------------------
def merge_shadow_memory():
    main = load_data("memory.json")
    shadow = load_data("shadow_memory.json")

    main_data = main.get("data", {})
    shadow_data = shadow.get("data", {})

    merged_phrases = 0
    added_responses = 0

    for phrase, responses in shadow_data.items():

        new_responses = []
        for r in responses:
            if isinstance(r, str):
                new_responses.append({"text": r, "weight": 1})
            elif isinstance(r, dict) and "text" in r:
                new_responses.append({"text": r["text"], "weight": r.get("weight", 1)})

        if phrase not in main_data:
            main_data[phrase] = new_responses
            merged_phrases += 1
        else:
            existing = [x["text"] for x in main_data[phrase]]
            for r in new_responses:
                if r["text"] not in existing:
                    main_data[phrase].append(r)
                    added_responses += 1

    if merged_phrases or added_responses:
        main["data"] = main_data
        save_data("memory.json", main)

        shadow["data"] = {}
        save_data("shadow_memory.json", shadow)

    return merged_phrases, added_responses


# ------------------------------
# ğŸ§  Ø¹Ù…Ù„ÛŒØ§Øª Ø§ØµÙ„ÛŒ Ø±Ø´Ø¯ Ù‡ÙˆØ´
# ------------------------------
async def analyze_and_grow(bot=None):

    ensure_memory_files()

    prev_stats = load_stats()
    before = {
        "phrases": prev_stats.get("phrases", 0),
        "responses": prev_stats.get("responses", 0)
    }

    # â†’ Ø§Ø¯ØºØ§Ù… Ø­Ø§ÙØ¸Ù‡ Ø³Ø§ÛŒÙ‡
    merged_phrases, added_responses = merge_shadow_memory()

    # â†’ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ
    try:
        clean_duplicates()
    except Exception as e:
        print(f"[AutoBrain] Clean failed: {e}")

    # â†’ ØªÙ‚ÙˆÛŒØª ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ
    try:
        reinforce_data = reinforce_learning(verbose=False)
    except Exception as e:
        print(f"[AutoBrain] Reinforce failed: {e}")
        reinforce_data = {"strengthened": 0, "removed": 0}

    # â†’ Ø¢Ù…Ø§Ø± Ø¬Ø¯ÛŒØ¯
    current = get_stats()

    # â†’ Ø¬Ù…Ù„Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®Ù„Ø§Ù‚
    creative = []
    for _ in range(random.randint(2, 5)):
        s = generate_sentence()
        creative.append(s)
        try:
            auto_learn_from_text(s)
        except Exception:
            pass

    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ Ø³Ø§ÛŒÙ‡
    shadow = load_data("shadow_memory.json")
    for text in creative:
        shadow["data"][f"âœ¨ {text}"] = ["ğŸ’¡ Ø¬Ù…Ù„Ù‡â€ŒÛŒ Ø³Ø§Ø®ØªÙ‡â€ŒØ´Ø¯Ù‡ ØªÙˆØ³Ø· Ù‡ÙˆØ´ Ø®ÙˆØ¯Ú©Ø§Ø±"]
    save_data("shadow_memory.json", shadow)

    # â†’ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù‡ÙˆØ´
    try:
        aiq = evaluate_intelligence()
    except Exception as e:
        aiq = {"iq": 0, "level": "âŒ Ø®Ø·Ø§", "summary": str(e)}

    # â†’ Ø°Ø®ÛŒØ±Ù‡ Ø¢Ù…Ø§Ø±
    stats = {
        "phrases": current["phrases"],
        "responses": current["responses"],
        "runs": prev_stats.get("runs", 0) + 1,
        "last_update": datetime.now().strftime("%Y-%m-%d %H:%M")
    }
    save_stats(stats)

    # â†’ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ
    report = (
        f"ğŸ¤– <b>Ú¯Ø²Ø§Ø±Ø´ Ø±Ø´Ø¯ Ù‡ÙˆØ´ Ø®ÙˆØ¯Ú©Ø§Ø±</b>\n"
        f"ğŸ§© Ø§Ø¯ØºØ§Ù…â€ŒØ´Ø¯Ù‡: <b>{merged_phrases}</b>\n"
        f"ğŸ’¬ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯: <b>{added_responses}</b>\n"
        f"âœ¨ Ø®Ù„Ø§Ù‚ÛŒØªâ€ŒÙ‡Ø§: <b>{len(creative)}</b>\n\n"
        f"ğŸ“ˆ Ø¬Ù…Ù„Ø§Øª: {before['phrases']} â†’ {stats['phrases']}\n"
        f"ğŸ’­ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§: {before['responses']} â†’ {stats['responses']}\n\n"
        f"ğŸ§  IQ: <b>{aiq['iq']}</b>\n"
        f"ğŸŒŸ Ø³Ø·Ø­: {aiq['level']}\n"
        f"{aiq['summary']}\n\n"
        f"ğŸ•“ Ø²Ù…Ø§Ù†: {stats['last_update']}\n"
        f"ğŸ” Ø§Ø¬Ø±Ø§Ù‡Ø§: <b>{stats['runs']}</b>"
    )

    print(report)

    # =====================
    # ğŸ›¡ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ÙÙ‚Ø· Ø§Ú¯Ø±:
    # 1) bot ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
    # 2) Ø§Ø¯Ù…ÛŒÙ† Ø¢Ù†Ø±Ø§ Ø§Ø³ØªØ§Ø±Øª Ú©Ø±Ø¯Ù‡
    # =====================
    if bot:
        try:
            await bot.send_message(
                chat_id=ADMIN_ID,
                text=report,
                parse_mode="HTML",
                disable_notification=True
            )
        except Exception as e:
            print(f"[Brain Report Error] {e}")


# ------------------------------
# ğŸ” Ø­Ù„Ù‚Ù‡ Û¶ Ø³Ø§Ø¹ØªÙ‡
# ------------------------------
async def start_auto_brain_loop(bot):
    while True:
        try:
            await analyze_and_grow(bot)
        except Exception as e:
            print(f"[AutoBrain Loop Error] {e}")
        await asyncio.sleep(6 * 60 * 60)
